{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYmM/AUErqHudU5IXyKONK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoSourang/Machine-Learning-Specialization_DeepLearning.AI/blob/main/Logistic_Final_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression & Cost"
      ],
      "metadata": {
        "id": "qcAe8v2A8jxj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnv0ghuN8RZC"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "  \"\"\" Computes the predicted output y, using the sigmoid function\n",
        "  for logistc regression\"\"\"\n",
        "\n",
        "  z = 1 / (1 + np.exp(-x))\n",
        "  return z\n",
        "\n",
        "def calculate_cost_logistic(x, y, w, b):\n",
        "  \"\"\" Run logistic regression given a set on specific inputs and calculates the cost\n",
        "      for the model\n",
        "\n",
        "      x: matrix: Input features for the model, has the following shape (m,n)\n",
        "      y: ndarray: True values of y\n",
        "      w: ndarray: The paramaters for each corresponding feature\n",
        "      b: float: The bias for the model\n",
        "  \"\"\"\n",
        "  # Number of input featurs\n",
        "  m = x.shape[0]\n",
        "\n",
        "  # Model's Cost\n",
        "  cost = 0.0\n",
        "\n",
        "  for i in range(m):\n",
        "    fwb = np.dot(x[i], w) + b\n",
        "    yhat = sigmoid(fwb)\n",
        "    loss = -y[i] * np.log(yhat) - (1 - y[i] * np.log(1 - yhat))\n",
        "    cost += loss\n",
        "\n",
        "  cost = cost / m\n",
        "  return cost"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent"
      ],
      "metadata": {
        "id": "dbVf4EsK_bAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_derivative_logistic(x, y, w, b)\n",
        "   \"\"\" Caculates the derivative of w, b for logsitic regresssion\n",
        "\n",
        "      x: matrix: Input features for the model, has the following shape (m,n)\n",
        "      y: ndarray: True values of y\n",
        "      w: ndarray: The paramaters for each corresponding feature\n",
        "      b: float: The bias for the model\n",
        "  \"\"\"\n",
        "\n",
        "  #Number of training feature and parameters resepctively\n",
        "  m = x.shape[0]\n",
        "  n = x.shape[1]\n",
        "\n",
        "  # dertivatives for w, b respectively\n",
        "  dj_dw = np.zeros(n)\n",
        "  dj_db = 0\n",
        "\n",
        "  for i in range(m):\n",
        "    fwb = np.dot(x[i], w) + b\n",
        "    yhat = sigmoid(fwb)\n",
        "    dj_dw += (y[i] - yhat) * x[i]\n",
        "    dj_db += (y[i]- yhat)\n",
        "\n",
        "  dj_dw = dj_dw / m\n",
        "  dj_db = dj_db / m\n",
        "\n",
        "  return dj_dw , dj_db\n",
        "\n",
        "def run_gradient_descent_logistic(x, y, int_w, int_b, alpha, num_iter):\n",
        "   \"\"\" Caculates the derivative of w, b for logsitic regresssion\n",
        "\n",
        "      x: matrix: Input features for the model, has the following shape (m,n)\n",
        "      y: ndarray: True values of y\n",
        "      w: ndarray: The paramaters for each corresponding feature\n",
        "      b: float: The bias for the model\n",
        "      alpha: float: The learning rate for the model\n",
        "      num_iter: the number of times we want to run grandient descent\n",
        "  \"\"\"\n",
        "\n",
        "  # Number of parameters\n",
        "  n = x.shape(0)\n",
        "\n",
        "  # Updated values of W, B\n",
        "  new_w = int_w\n",
        "  new_b = int_b\n",
        "\n",
        "  # Costs at each iteration of gradient descent\n",
        "  costs = [0]\n",
        "\n",
        "  for i in range(num_iter):\n",
        "    dj_dw , dj_db = calculate_derivative_logistic(x, y, new_w, new_b)\n",
        "    cost.append(calculate_cost_logistic(x, y, new_w, new_b))\n",
        "    new_w = new_w - alpha * dj_dw\n",
        "    new_b = new_b - alpha * dj_db\n",
        "\n",
        "  return costs , new_w , new_b"
      ],
      "metadata": {
        "id": "Kagvjgne_kVo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}